---

# IBM Data Wrangling Project

This repository contains a data wrangling project completed as part of the **IBM Data Science Professional Certificate**.
The project demonstrates skills in **data cleaning, transformation, feature engineering, and preparation for analysis** using Python and pandas.

## ğŸ“Œ Project Overview

The dataset used is the [Automobile dataset](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv), which contains specifications and pricing information for various car models.

The notebook walks through the process of:

* Importing raw data
* Handling **missing values** with imputation and replacement
* Converting data types
* Creating new variables through mathematical transformations
* Normalizing continuous variables
* **Binning** numerical features
* **Encoding categorical variables** with dummy variables
* Exporting the cleaned dataset for future analysis

## ğŸ“‚ Repository Contents

* `DataWrangling-checkpoint.ipynb` â€” Jupyter notebook containing all steps of the data wrangling process
* `clean_df.csv` â€” Exported cleaned dataset ready for further analysis (generated by the notebook)

## âš™ï¸ Technologies Used

* **Python 3.x**
* **pandas** â€” data manipulation and cleaning
* **NumPy** â€” numerical operations
* **Matplotlib** â€” visualization and binning histograms
* **Jupyter Notebook** â€” interactive environment for running and documenting code

## ğŸš€ Key Skills Demonstrated

* Identifying and imputing **missing data**
* **Type conversion** for numerical and categorical features
* Feature scaling and normalization
* Engineering new features (e.g., converting MPG â†’ L/100KM)
* **Binning** continuous variables into categories
* **One-hot encoding** categorical variables
* Creating a cleaned, structured dataset suitable for modeling

## â–¶ï¸ How to Run

1. Clone this repository:

   ```bash
   git clone https://github.com/ZULUM000/IBM-DATA-WRANGLING.git
   ```
2. Navigate to the repo:

   ```bash
   cd IBM-DATA-WRANGLING
   ```
3. Install required packages (if not already installed):

   ```bash
   pip install pandas numpy matplotlib jupyter
   ```
4. Launch Jupyter Notebook:

   ```bash
   jupyter notebook
   ```
5. Open `DataWrangling-checkpoint.ipynb` and run the cells step by step.

## ğŸ“Š Sample Output

* Cleaned dataset with **30+ columns** after transformation
* Histograms of horsepower distribution with categorical bins (Low / Medium / High)
* Encoded categorical variables for use in ML pipelines
* Final structured dataset exported as `clean_df.csv`

## ğŸ“ˆ Future Work

* Exploratory Data Analysis (EDA) on cleaned dataset
* Building predictive models (e.g., regression for car price prediction)
* Creating interactive dashboards with visualization libraries like Seaborn or Plotly

---

âœ¨ This project highlights proficiency in **data wrangling and preprocessing** â€” a critical step in any data science pipeline.

---

